{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      3\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload()\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\Dishcovery\\.venv\\lib\\site-packages\\nltk\\__init__.py:146\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjsontags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# PACKAGES\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassify\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\Dishcovery\\.venv\\lib\\site-packages\\nltk\\chunk\\__init__.py:155\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Natural Language Toolkit: Chunkers\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (C) 2001-2024 NLTK Project\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# For license information, see LICENSE.TXT\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mClasses and interfaces for identifying non-overlapping linguistic\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03mgroups (such as base noun phrases) in unrestricted text.  This task is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03m     pattern is valid.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChunkParserI\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnamed_entity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Maxent_NE_Chunker\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregexp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegexpChunkParser, RegexpParser\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\Dishcovery\\.venv\\lib\\site-packages\\nltk\\chunk\\api.py:13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Natural Language Toolkit: Chunk parsing API\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (C) 2001-2024 NLTK Project\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m##  Chunk Parser Interface\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m##//////////////////////////////////////////////////////\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChunkScore\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParserI\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\Dishcovery\\.venv\\lib\\site-packages\\nltk\\chunk\\util.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy \u001b[38;5;28;01mas\u001b[39;00m _accuracy\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_tag\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m str2tuple\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tree\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\Dishcovery\\.venv\\lib\\site-packages\\nltk\\tag\\__init__.py:70\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03mNLTK Taggers\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03misort:skip_file\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TaggerI\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m str2tuple, tuple2str, untag\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     73\u001b[0m     SequentialBackoffTagger,\n\u001b[0;32m     74\u001b[0m     ContextTagger,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m     ClassifierBasedPOSTagger,\n\u001b[0;32m     84\u001b[0m )\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')  \n",
    "nltk.download('averaged_perceptron_tagger')  \n",
    "nltk.download('wordnet')  \n",
    "nltk.download('omw-1.4')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def convert_pos_tag_to_wordnet(tag):\n",
    "    tag = tag.upper()\n",
    "    if tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    return None \n",
    "\n",
    "def lemmatize_word(word, tag):\n",
    "    wordnet_tag = convert_pos_tag_to_wordnet(tag)\n",
    "    if wordnet_tag:\n",
    "        return lemmatizer.lemmatize(word, wordnet_tag)\n",
    "    return word  \n",
    "\n",
    "def clean_ingredient_text(ingredient):\n",
    "    units = [\n",
    "        \"cup\", \"cups\", \"teaspoon\", \"tsp\", \"tablespoon\", \"tbsp\", \"oz\", \"ounce\", \"ounces\",\n",
    "        \"gram\", \"grams\", \"kg\", \"ml\", \"liter\", \"liters\", \"lbs\", \"pound\", \"pounds\", \"pack\",\n",
    "        \"pcs\", \"pieces\", \"slices\", \"dash\", \"pinch\", \"lb\", \"can\"\n",
    "    ]\n",
    "    \n",
    "    unwanted_phrases = [\n",
    "        \"taste\", \"canned\", \"is best\", \"package\", \"or\", \"drain\", \"rinse\", \"with\", \"is\", \"best\",\n",
    "        \"to\", \"cooked\", \"chopped\", \"cook\", \"chop\", \"not\", \"evaporate\", \"cut\", \"into\", \"tablespoons\",\n",
    "        \"teaspoons\", \"but\", \"I\", \"prefer\", \"bite\", \"sized\", \"cubes\", \"and\", \"cans\", \"at\", \"room\",\n",
    "        \"temperature\", \"pkge\", \"in\", \"half\", \"thinly\", \"diced\", \"dice\", \"slice\", \"sliced\",\n",
    "        \"strip\", \"strips\", \"large\", \"small\"\n",
    "    ]\n",
    "\n",
    "    # Remove unwanted words and collapse multiple spaces\n",
    "    ingredient = re.sub(r'\\b\\d+(\\.\\d+)?\\b', '', ingredient)  \n",
    "    ingredient = re.sub(r'\\b(?:' + '|'.join(units) + r')\\b', '', ingredient, flags=re.IGNORECASE)  \n",
    "    ingredient = re.sub(r'\\b(?:' + '|'.join(unwanted_phrases) + r')\\b', '', ingredient, flags=re.IGNORECASE) \n",
    "    ingredient = re.sub(r'[^\\w\\s]', '', ingredient)\n",
    "    ingredient = re.sub(r'\\s+', ' ', ingredient).strip()\n",
    "\n",
    "    return ingredient\n",
    "\n",
    "def process_ingredient(ingredient):\n",
    "    cleaned_ingredient = clean_ingredient_text(ingredient)\n",
    "    tokens = word_tokenize(cleaned_ingredient)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    lemmatized_tokens = [lemmatize_word(word, tag) for word, tag in tagged_tokens]\n",
    "    \n",
    "    return \" \".join(lemmatized_tokens)\n",
    "\n",
    "def process_ingredient_list(ingredient_list):\n",
    "    ingredients = [ingredient.strip() for ingredient in ingredient_list.split(',')]\n",
    "    processed_ingredients = [process_ingredient(ingredient) for ingredient in ingredients]\n",
    "    \n",
    "    return ', '.join(processed_ingredients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>NLP_Ingredients</th>\n",
       "      <th>Cleaned_Ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71247</td>\n",
       "      <td>Cherry Streusel Cobbler</td>\n",
       "      <td>cherry pie filling, egg, sweeten condensed mil...</td>\n",
       "      <td>['condensed milk', 'margarine', 'self-rising f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76133</td>\n",
       "      <td>Reuben and Swiss Casserole Bake</td>\n",
       "      <td>corn beef, , thousand island dress, sauerkraut...</td>\n",
       "      <td>['corned beef', 'sauerkraut', 'swiss cheese', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>503816</td>\n",
       "      <td>Yam-Pecan Recipe</td>\n",
       "      <td>unsalted butter, , sugar, vegetable oil, egg, ...</td>\n",
       "      <td>['salt', 'sugar', 'all - purpose flour', 'vege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>418749</td>\n",
       "      <td>Tropical Orange Layer Cake</td>\n",
       "      <td>orange cake mix, instant vanilla pudding, oran...</td>\n",
       "      <td>['orange gelatin', 'instant vanilla pudding', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>392934</td>\n",
       "      <td>Safe to Eat Raw Chocolate Chip Oreo Cookie \"do...</td>\n",
       "      <td>butter, , brown sugar, granulate sugar, milk, ...</td>\n",
       "      <td>['salt', 'granulated sugar', 'vanilla', 'choco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>532245</td>\n",
       "      <td>Chicken and Petite Carrots</td>\n",
       "      <td>chicken breast, cutlet, bag of petite carrot, ...</td>\n",
       "      <td>['seasoning', 'margarine', 'carrots', 'chicken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>489452</td>\n",
       "      <td>Teriyaki Pork Chops</td>\n",
       "      <td>bottle teriyaki sauce, pork chop</td>\n",
       "      <td>['pork chops', 'teriyaki sauce']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>126368</td>\n",
       "      <td>Bobbie's Pie Crust</td>\n",
       "      <td>flour, sugar, salt, milk, oil</td>\n",
       "      <td>['sugar', 'milk', 'salt', 'flour']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>306467</td>\n",
       "      <td>Quick Bolognese Sauce</td>\n",
       "      <td>light olive oil, yellow onion, , celery rib, ,...</td>\n",
       "      <td>['crushed tomatoes', 'ground chuck', 'dry red ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>318331</td>\n",
       "      <td>Granny's Butter Rolls</td>\n",
       "      <td>biscuit mix, water, granulate sugar, butter, s...</td>\n",
       "      <td>['granulated sugar', 'butter', 'biscuit mix', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               Name  \\\n",
       "0   71247                            Cherry Streusel Cobbler   \n",
       "1   76133                    Reuben and Swiss Casserole Bake   \n",
       "2  503816                                   Yam-Pecan Recipe   \n",
       "3  418749                         Tropical Orange Layer Cake   \n",
       "4  392934  Safe to Eat Raw Chocolate Chip Oreo Cookie \"do...   \n",
       "5  532245                         Chicken and Petite Carrots   \n",
       "6  489452                                Teriyaki Pork Chops   \n",
       "7  126368                                 Bobbie's Pie Crust   \n",
       "8  306467                              Quick Bolognese Sauce   \n",
       "9  318331                              Granny's Butter Rolls   \n",
       "\n",
       "                                     NLP_Ingredients  \\\n",
       "0  cherry pie filling, egg, sweeten condensed mil...   \n",
       "1  corn beef, , thousand island dress, sauerkraut...   \n",
       "2  unsalted butter, , sugar, vegetable oil, egg, ...   \n",
       "3  orange cake mix, instant vanilla pudding, oran...   \n",
       "4  butter, , brown sugar, granulate sugar, milk, ...   \n",
       "5  chicken breast, cutlet, bag of petite carrot, ...   \n",
       "6                   bottle teriyaki sauce, pork chop   \n",
       "7                      flour, sugar, salt, milk, oil   \n",
       "8  light olive oil, yellow onion, , celery rib, ,...   \n",
       "9  biscuit mix, water, granulate sugar, butter, s...   \n",
       "\n",
       "                                 Cleaned_Ingredients  \n",
       "0  ['condensed milk', 'margarine', 'self-rising f...  \n",
       "1  ['corned beef', 'sauerkraut', 'swiss cheese', ...  \n",
       "2  ['salt', 'sugar', 'all - purpose flour', 'vege...  \n",
       "3  ['orange gelatin', 'instant vanilla pudding', ...  \n",
       "4  ['salt', 'granulated sugar', 'vanilla', 'choco...  \n",
       "5  ['seasoning', 'margarine', 'carrots', 'chicken...  \n",
       "6                   ['pork chops', 'teriyaki sauce']  \n",
       "7                 ['sugar', 'milk', 'salt', 'flour']  \n",
       "8  ['crushed tomatoes', 'ground chuck', 'dry red ...  \n",
       "9  ['granulated sugar', 'butter', 'biscuit mix', ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read documentation!, use ast literal eval\n",
    "# Try catch with literal eval, converters\n",
    "df = pd.read_csv('Data/recipes_food_com_cleaned.csv')\n",
    "df['NLP_Ingredients'] = df['IngredientsRaw'].apply(process_ingredient_list)\n",
    "df = df[['ID', 'Name','NLP_Ingredients', 'Cleaned_Ingredients']]\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>NLP_Ingredients</th>\n",
       "      <th>Cleaned_Ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71247</td>\n",
       "      <td>Cherry Streusel Cobbler</td>\n",
       "      <td>cherry pie filling, egg, sweeten condensed mil...</td>\n",
       "      <td>['condensed milk', 'margarine', 'self-rising f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76133</td>\n",
       "      <td>Reuben and Swiss Casserole Bake</td>\n",
       "      <td>corn beef, thousand island dress, sauerkraut, ...</td>\n",
       "      <td>['corned beef', 'sauerkraut', 'swiss cheese', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>503816</td>\n",
       "      <td>Yam-Pecan Recipe</td>\n",
       "      <td>unsalted butter, sugar, vegetable oil, egg, li...</td>\n",
       "      <td>['salt', 'sugar', 'all - purpose flour', 'vege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>418749</td>\n",
       "      <td>Tropical Orange Layer Cake</td>\n",
       "      <td>orange cake mix, instant vanilla pudding, oran...</td>\n",
       "      <td>['orange gelatin', 'instant vanilla pudding', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>392934</td>\n",
       "      <td>Safe to Eat Raw Chocolate Chip Oreo Cookie \"do...</td>\n",
       "      <td>butter, brown sugar, granulate sugar, milk, va...</td>\n",
       "      <td>['salt', 'granulated sugar', 'vanilla', 'choco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>532245</td>\n",
       "      <td>Chicken and Petite Carrots</td>\n",
       "      <td>chicken breast, cutlet, bag of petite carrot, ...</td>\n",
       "      <td>['seasoning', 'margarine', 'carrots', 'chicken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>489452</td>\n",
       "      <td>Teriyaki Pork Chops</td>\n",
       "      <td>bottle teriyaki sauce, pork chop</td>\n",
       "      <td>['pork chops', 'teriyaki sauce']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>126368</td>\n",
       "      <td>Bobbie's Pie Crust</td>\n",
       "      <td>flour, sugar, salt, milk, oil</td>\n",
       "      <td>['sugar', 'milk', 'salt', 'flour']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>306467</td>\n",
       "      <td>Quick Bolognese Sauce</td>\n",
       "      <td>light olive oil, yellow onion, celery rib, car...</td>\n",
       "      <td>['crushed tomatoes', 'ground chuck', 'dry red ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>318331</td>\n",
       "      <td>Granny's Butter Rolls</td>\n",
       "      <td>biscuit mix, water, granulate sugar, butter, s...</td>\n",
       "      <td>['granulated sugar', 'butter', 'biscuit mix', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               Name  \\\n",
       "0   71247                            Cherry Streusel Cobbler   \n",
       "1   76133                    Reuben and Swiss Casserole Bake   \n",
       "2  503816                                   Yam-Pecan Recipe   \n",
       "3  418749                         Tropical Orange Layer Cake   \n",
       "4  392934  Safe to Eat Raw Chocolate Chip Oreo Cookie \"do...   \n",
       "5  532245                         Chicken and Petite Carrots   \n",
       "6  489452                                Teriyaki Pork Chops   \n",
       "7  126368                                 Bobbie's Pie Crust   \n",
       "8  306467                              Quick Bolognese Sauce   \n",
       "9  318331                              Granny's Butter Rolls   \n",
       "\n",
       "                                     NLP_Ingredients  \\\n",
       "0  cherry pie filling, egg, sweeten condensed mil...   \n",
       "1  corn beef, thousand island dress, sauerkraut, ...   \n",
       "2  unsalted butter, sugar, vegetable oil, egg, li...   \n",
       "3  orange cake mix, instant vanilla pudding, oran...   \n",
       "4  butter, brown sugar, granulate sugar, milk, va...   \n",
       "5  chicken breast, cutlet, bag of petite carrot, ...   \n",
       "6                   bottle teriyaki sauce, pork chop   \n",
       "7                      flour, sugar, salt, milk, oil   \n",
       "8  light olive oil, yellow onion, celery rib, car...   \n",
       "9  biscuit mix, water, granulate sugar, butter, s...   \n",
       "\n",
       "                                 Cleaned_Ingredients  \n",
       "0  ['condensed milk', 'margarine', 'self-rising f...  \n",
       "1  ['corned beef', 'sauerkraut', 'swiss cheese', ...  \n",
       "2  ['salt', 'sugar', 'all - purpose flour', 'vege...  \n",
       "3  ['orange gelatin', 'instant vanilla pudding', ...  \n",
       "4  ['salt', 'granulated sugar', 'vanilla', 'choco...  \n",
       "5  ['seasoning', 'margarine', 'carrots', 'chicken...  \n",
       "6                   ['pork chops', 'teriyaki sauce']  \n",
       "7                 ['sugar', 'milk', 'salt', 'flour']  \n",
       "8  ['crushed tomatoes', 'ground chuck', 'dry red ...  \n",
       "9  ['granulated sugar', 'butter', 'biscuit mix', ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NLP_Ingredients'] = df['NLP_Ingredients'].str.split(',').apply(\n",
    "    lambda x: ', '.join([ingredient.strip() for ingredient in x if ingredient.strip()])\n",
    ")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv('NLTK.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egg, egg, onion, evaporate milk\n"
     ]
    }
   ],
   "source": [
    "list = \"eggs, egg, chopped onions, evaporated milk\"\n",
    "print(process_ingredient_list(list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
