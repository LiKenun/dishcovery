{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS TO GET THE INGREDIENTS INTO THE CORRECT FORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hijer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hijer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hijer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\hijer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')  \n",
    "nltk.download('averaged_perceptron_tagger')  \n",
    "nltk.download('wordnet')  \n",
    "nltk.download('omw-1.4')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/4 cup unsalted butter, /2 cup sugar, /2 cup\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def convert_pos_tag_to_wordnet(tag):\n",
    "    tag = tag.upper()\n",
    "    if tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    return None \n",
    "\n",
    "def lemmatize_word(word, tag):\n",
    "    wordnet_tag = convert_pos_tag_to_wordnet(tag)\n",
    "    if wordnet_tag:\n",
    "        return lemmatizer.lemmatize(word, wordnet_tag)\n",
    "    return word  \n",
    "\n",
    "fractions = {\n",
    "    u'\\u00BD': '.50',\n",
    "    u'\\u00BC': '.25',\n",
    "    u'\\u00BE': '.75',\n",
    "    u'\\u2153': '.33',\n",
    "    u'\\u2154': '.67',\n",
    "    u'\\u2155': '.20',\n",
    "    u'\\u2156': '.40',\n",
    "    u'\\u2157': '.60',\n",
    "    u'\\u2158': '.80',\n",
    "    u'\\u2159': '.17',\n",
    "    u'\\u215A': '.83',\n",
    "    u'\\u215B': '.13',\n",
    "    u'\\u215C': '.38',\n",
    "    u'\\u215D': '.63',\n",
    "    u'\\u215E': '.88'\n",
    "}\n",
    "\n",
    "unwanted_phrases = set([\n",
    "    \"taste\", \"canned\", \"is best\", \"package\", \"or\", \"drain\", \"rinse\", \"with\", \"is\", \"best\",\n",
    "    \"to\", \"cooked\", \"chopped\", \"cook\", \"chop\", \"not\", \"evaporate\", \"cut\", \"into\", \"but\", \"I\",\n",
    "    \"prefer\", \"bite\", \"sized\", \"cubes\", \"and\", \"cans\", \"at\", \"room\", \"temperature\", \"pkge\",\n",
    "    \"in\", \"half\", \"thinly\", \"diced\", \"dice\", \"slice\", \"sliced\", \"strip\", \"strips\", \"large\", \"small\"\n",
    "])\n",
    "unwanted_phrases_pattern = re.compile(r'\\b(?:' + '|'.join(map(re.escape, unwanted_phrases)) + r')\\b', re.IGNORECASE)\n",
    "range_pattern = re.compile(r'\\(([\\d/.\\s]+)-([\\d/.\\s]+)\\)')\n",
    "leading_quantity_pattern = re.compile(r'^\\d+\\s*\\(([^)]+)\\)')\n",
    "standalone_numbers_pattern = re.compile(r'\\b\\d+(\\.\\d+)?\\b(?!\\s*[a-zA-Z])')\n",
    "punctuation_pattern = re.compile(r'[^\\w\\s/]')\n",
    "multiple_spaces_pattern = re.compile(r'\\s+')\n",
    "\n",
    "def convert_fractions(line):\n",
    "    for key, value in fractions.items():\n",
    "        if key in line:\n",
    "            line = line.replace(key, value)\n",
    "            matches = re.findall(r\"\\d\\s*(?=\" + re.escape(value) + \")\", line)\n",
    "            for match in matches:\n",
    "                number = float(match)\n",
    "                new_value = float(value)\n",
    "                multiplier = 1 + new_value\n",
    "                result = number * multiplier\n",
    "                string_result = str(result)\n",
    "                line = line.replace(match + value, string_result)\n",
    "    return line\n",
    "\n",
    "def clean_ingredient_text(ingredient):\n",
    "    # Remove unwanted phrases\n",
    "    ingredient = unwanted_phrases_pattern.sub('', ingredient)\n",
    "    \n",
    "    # Handle ranges like \"(1/2 - 1)\" by keeping the upper bound\n",
    "    ingredient = range_pattern.sub(lambda m: m.group(2).strip(), ingredient)\n",
    "    \n",
    "    # Keep valid fractions like \"1/2\" or \"3/4\"\n",
    "    ingredient = re.sub(r'\\b(\\d+/\\d+)', r'\\1', ingredient)\n",
    "    \n",
    "    # Remove leading quantities in parentheses, e.g., \"2 (21 ounce)\" -> \"21 ounce\"\n",
    "    ingredient = leading_quantity_pattern.sub(r'\\1', ingredient)\n",
    "    \n",
    "    # Remove any standalone numbers not tied to units\n",
    "    ingredient = standalone_numbers_pattern.sub('', ingredient)\n",
    "    \n",
    "    # Remove punctuation but keep slashes (for fractions) and collapse multiple spaces\n",
    "    ingredient = punctuation_pattern.sub('', ingredient)\n",
    "    ingredient = multiple_spaces_pattern.sub(' ', ingredient).strip()\n",
    "\n",
    "    return ingredient\n",
    "\n",
    "def process_ingredient(ingredient):\n",
    "    ingredient = convert_fractions(ingredient)\n",
    "    cleaned_ingredient = clean_ingredient_text(ingredient)\n",
    "    tokens = word_tokenize(cleaned_ingredient)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    lemmatized_tokens = [lemmatize_word(word, tag) for word, tag in tagged_tokens]\n",
    "    \n",
    "    return \" \".join(lemmatized_tokens)\n",
    "\n",
    "def process_ingredient_list(ingredient_list):\n",
    "    ingredients = [ingredient.strip() for ingredient in ingredient_list.split(',')]\n",
    "    processed_ingredients = [process_ingredient(ingredient) for ingredient in ingredients]\n",
    "    \n",
    "    return ', '.join(processed_ingredients)\n",
    "\n",
    "# Test the function with an example list\n",
    "example_ingredients_list = \"3/4 cup unsalted butter, 1/2 cup sugar, 1/2 cup\"\n",
    "processed_ingredients_list = process_ingredient_list(example_ingredients_list)\n",
    "print(processed_ingredients_list)  # Output: \"3/4 cup unsalted butter, 1/2 cup sugar, 1/2 cup\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 ounce cherry pie filling, 2 egg, 14 ounce, 1 lb corn beef\n"
     ]
    }
   ],
   "source": [
    "#Best verion can do it all except handle ranges\n",
    "import re\n",
    "from fractions import Fraction\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import nltk\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def convert_pos_tag_to_wordnet(tag):\n",
    "    tag = tag.upper()\n",
    "    if tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    return None \n",
    "\n",
    "def lemmatize_word(word, tag):\n",
    "    wordnet_tag = convert_pos_tag_to_wordnet(tag)\n",
    "    if wordnet_tag:\n",
    "        return lemmatizer.lemmatize(word, wordnet_tag)\n",
    "    return word  \n",
    "\n",
    "def convert_fractions_to_decimals(text):\n",
    "    def fraction_to_decimal(match):\n",
    "        try:\n",
    "            fraction = match.group(0)\n",
    "            return str(round(float(Fraction(fraction)), 2))\n",
    "        except ValueError:\n",
    "            return fraction  # Return the original if conversion fails\n",
    "\n",
    "    return re.sub(r'\\b\\d+/\\d+\\b', fraction_to_decimal, text)\n",
    "\n",
    "def clean_ingredient_text(ingredient):\n",
    "    # List of unwanted phrases to remove\n",
    "    unwanted_phrases = [\n",
    "        \"taste\", \"canned\", \"is best\", \"package\", \"or\", \"drain\", \"rinse\", \"with\", \"is\", \"best\",\n",
    "        \"to\", \"cooked\", \"chopped\", \"cook\", \"chop\", \"not\", \"evaporate\", \"cut\", \"into\", \"but\", \"I\",\n",
    "        \"prefer\", \"bite\", \"sized\", \"cubes\", \"and\", \"cans\", \"at\", \"room\", \"temperature\", \"pkge\",\n",
    "        \"in\", \"half\", \"thinly\", \"diced\", \"dice\", \"slice\", \"sliced\", \"strip\", \"strips\", \"large\", \"small\"\n",
    "    ]\n",
    "    \n",
    "    # Remove unwanted phrases\n",
    "    ingredient = re.sub(r'\\b(?:' + '|'.join(unwanted_phrases) + r')\\b', '', ingredient, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Handle ranges like \"(1/2 - 1)\" by keeping the upper bound\n",
    "    ingredient = re.sub(r'\\(([\\d/.\\s]+)-([\\d/.\\s]+)\\)', lambda m: m.group(2).strip(), ingredient)\n",
    "    \n",
    "    # Convert fractions to decimals\n",
    "    ingredient = convert_fractions_to_decimals(ingredient)\n",
    "    \n",
    "    # Remove leading quantities in parentheses, e.g., \"2 (21 ounce)\" -> \"21 ounce\"\n",
    "    ingredient = re.sub(r'\\d+\\s*\\(([^)]+)\\)', r'\\1', ingredient)\n",
    "    \n",
    "    # Remove punctuation but keep slashes (for fractions) and collapse multiple spaces\n",
    "    ingredient = re.sub(r'[^\\w\\s/.]', '', ingredient)\n",
    "    ingredient = re.sub(r'\\s+', ' ', ingredient).strip()\n",
    "\n",
    "    return ingredient\n",
    "\n",
    "def process_ingredient(ingredient):\n",
    "    cleaned_ingredient = clean_ingredient_text(ingredient)\n",
    "    tokens = word_tokenize(cleaned_ingredient)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    lemmatized_tokens = [lemmatize_word(word, tag) for word, tag in tagged_tokens]\n",
    "    \n",
    "    return \" \".join(lemmatized_tokens)\n",
    "\n",
    "def process_ingredient_list(ingredient_list):\n",
    "    ingredients = [ingredient.strip() for ingredient in ingredient_list.split(',')]\n",
    "    processed_ingredients = [process_ingredient(ingredient) for ingredient in ingredients]\n",
    "    \n",
    "    return ', '.join(processed_ingredients)\n",
    "\n",
    "# Test the function with an example list\n",
    "example_ingredients_list = \"2 (21 ounce) cherry pie filling, 2 egg, 1 (14 ounce), (1/2 - 1) lb corn beef\"\n",
    "processed_ingredients_list = process_ingredient_list(example_ingredients_list)\n",
    "print(processed_ingredients_list)  # Output: \"21 ounce cherry pie filling, 2 egg, 14 ounce, 1 lb corn beef\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 ounce cherry pie filling, 2 egg, 14 ounce, 1.0 lb corn beef, 2.0 cup milk\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from fractions import Fraction\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def convert_pos_tag_to_wordnet(tag):\n",
    "    tag = tag.upper()\n",
    "    if tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    return None \n",
    "\n",
    "def lemmatize_word(word, tag):\n",
    "    wordnet_tag = convert_pos_tag_to_wordnet(tag)\n",
    "    if wordnet_tag:\n",
    "        return lemmatizer.lemmatize(word, wordnet_tag)\n",
    "    return word  \n",
    "\n",
    "def convert_fractions_to_decimals(text):\n",
    "    \"\"\"\n",
    "    Converts fractions in the text to decimals.\n",
    "    Example: '1/2' -> '0.5', '3/4' -> '0.75'\n",
    "    \"\"\"\n",
    "    def fraction_to_decimal(match):\n",
    "        try:\n",
    "            fraction = match.group(0)\n",
    "            return str(round(float(Fraction(fraction)), 2))\n",
    "        except ValueError:\n",
    "            return fraction  # Return the original if conversion fails\n",
    "\n",
    "    return re.sub(r'\\b\\d+/\\d+\\b', fraction_to_decimal, text)\n",
    "\n",
    "def handle_ranges(text):\n",
    "    \"\"\"\n",
    "    Handles ranges like '(1/2 - 1)' or '(0.5 - 1)' and keeps the maximum value.\n",
    "    \"\"\"\n",
    "    def extract_max(match):\n",
    "        try:\n",
    "            # Extract both parts of the range\n",
    "            lower, upper = match.groups()\n",
    "            # Convert to float (handle fractions if necessary)\n",
    "            lower_value = float(Fraction(lower)) if '/' in lower else float(lower)\n",
    "            upper_value = float(Fraction(upper)) if '/' in upper else float(upper)\n",
    "            # Return the maximum value\n",
    "            return str(round(max(lower_value, upper_value), 2))\n",
    "        except ValueError:\n",
    "            return match.group(0)  # Return the original if conversion fails\n",
    "\n",
    "    return re.sub(r'\\(([\\d/.\\s]+)-([\\d/.\\s]+)\\)', extract_max, text)\n",
    "\n",
    "def clean_ingredient_text(ingredient):\n",
    "    # List of unwanted phrases to remove\n",
    "    unwanted_phrases = [\n",
    "        \"taste\", \"canned\", \"is best\", \"package\", \"or\", \"drain\", \"rinse\", \"with\", \"is\", \"best\",\n",
    "        \"to\", \"cooked\", \"chopped\", \"cook\", \"chop\", \"not\", \"evaporate\", \"cut\", \"into\", \"but\", \"I\",\n",
    "        \"prefer\", \"bite\", \"sized\", \"cubes\", \"and\", \"cans\", \"at\", \"room\", \"temperature\", \"pkge\",\n",
    "        \"in\", \"half\", \"thinly\", \"diced\", \"dice\", \"slice\", \"sliced\", \"strip\", \"strips\", \"large\", \"small\"\n",
    "    ]\n",
    "    \n",
    "    # Remove unwanted phrases\n",
    "    ingredient = re.sub(r'\\b(?:' + '|'.join(unwanted_phrases) + r')\\b', '', ingredient, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Handle ranges by keeping the maximum value\n",
    "    ingredient = handle_ranges(ingredient)\n",
    "    \n",
    "    # Convert fractions to decimals\n",
    "    ingredient = convert_fractions_to_decimals(ingredient)\n",
    "    \n",
    "    # Remove leading quantities in parentheses, e.g., \"2 (21 ounce)\" -> \"21 ounce\"\n",
    "    ingredient = re.sub(r'\\d+\\s*\\(([^)]+)\\)', r'\\1', ingredient)\n",
    "    \n",
    "    # Remove punctuation but keep slashes (for fractions) and collapse multiple spaces\n",
    "    ingredient = re.sub(r'[^\\w\\s/.]', '', ingredient)\n",
    "    ingredient = re.sub(r'\\s+', ' ', ingredient).strip()\n",
    "\n",
    "    return ingredient\n",
    "\n",
    "def process_ingredient(ingredient):\n",
    "    cleaned_ingredient = clean_ingredient_text(ingredient)\n",
    "    tokens = word_tokenize(cleaned_ingredient)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    lemmatized_tokens = [lemmatize_word(word, tag) for word, tag in tagged_tokens]\n",
    "    \n",
    "    return \" \".join(lemmatized_tokens)\n",
    "\n",
    "def process_ingredient_list(ingredient_list):\n",
    "    ingredients = [ingredient.strip() for ingredient in ingredient_list.split(',')]\n",
    "    processed_ingredients = [process_ingredient(ingredient) for ingredient in ingredients]\n",
    "    \n",
    "    return ', '.join(processed_ingredients)\n",
    "\n",
    "# Test the function with an example list\n",
    "example_ingredients_list = \"2 (21 ounce) cherry pie filling, 2 egg, 1 (14 ounce), (1/2 - 1) lb corn beef, (3/4 - 2) cup milk\"\n",
    "processed_ingredients_list = process_ingredient_list(example_ingredients_list)\n",
    "print(processed_ingredients_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 ounce cherry pie filling, 2 egg, 14 ounce, 1.0 lb corn beef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hijer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hijer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hijer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#CURRENT BEST 11/27 1:40\n",
    "import re\n",
    "from fractions import Fraction\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import nltk\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def convert_pos_tag_to_wordnet(tag):\n",
    "    tag = tag.upper()\n",
    "    if tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    return None \n",
    "\n",
    "def lemmatize_word(word, tag):\n",
    "    wordnet_tag = convert_pos_tag_to_wordnet(tag)\n",
    "    if wordnet_tag:\n",
    "        return lemmatizer.lemmatize(word, wordnet_tag)\n",
    "    return word  \n",
    "\n",
    "def convert_fractions_to_decimals(text):\n",
    "    \"\"\"\n",
    "    Converts fractions in the text to decimals.\n",
    "    Example: '1/2' -> '0.5', '3/4' -> '0.75'\n",
    "    \"\"\"\n",
    "    def fraction_to_decimal(match):\n",
    "        try:\n",
    "            fraction = match.group(0)\n",
    "            return str(round(float(Fraction(fraction)), 2))\n",
    "        except ValueError:\n",
    "            return fraction  # Return the original if conversion fails\n",
    "\n",
    "    return re.sub(r'\\b\\d+/\\d+\\b', fraction_to_decimal, text)\n",
    "\n",
    "def clean_ingredient_text(ingredient):\n",
    "    # List of unwanted phrases to remove\n",
    "    unwanted_phrases = [\n",
    "        \"taste\", \"canned\", \"is best\", \"package\", \"or\", \"drain\", \"rinse\", \"with\", \"is\", \"best\",\n",
    "        \"to\", \"cooked\", \"chopped\", \"cook\", \"chop\", \"not\", \"evaporate\", \"cut\", \"into\", \"but\", \"I\",\n",
    "        \"prefer\", \"bite\", \"sized\", \"cubes\", \"and\", \"cans\", \"at\", \"room\", \"temperature\", \"pkge\",\n",
    "        \"in\", \"half\", \"thinly\", \"diced\", \"dice\", \"slice\", \"sliced\", \"strip\", \"strips\", \"large\", \"small\"\n",
    "    ]\n",
    "    \n",
    "    # Remove unwanted phrases\n",
    "    ingredient = re.sub(r'\\b(?:' + '|'.join(unwanted_phrases) + r')\\b', '', ingredient, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Handle ranges like \"(1/2 - 1)\" by keeping the upper bound\n",
    "    ingredient = re.sub(r'\\(([\\d/.\\s]+)-([\\d/.\\s]+)\\)', lambda m: str(max(float(Fraction(m.group(1).strip())), float(Fraction(m.group(2).strip())))), ingredient)\n",
    "    \n",
    "    # Convert fractions to decimals\n",
    "    ingredient = convert_fractions_to_decimals(ingredient)\n",
    "    \n",
    "    # Remove leading quantities in parentheses, e.g., \"2 (21 ounce)\" -> \"21 ounce\"\n",
    "    ingredient = re.sub(r'\\d+\\s*\\(([^)]+)\\)', r'\\1', ingredient)\n",
    "    \n",
    "    # Remove punctuation but keep slashes (for fractions) and collapse multiple spaces\n",
    "    ingredient = re.sub(r'[^\\w\\s/.]', '', ingredient)\n",
    "    ingredient = re.sub(r'\\s+', ' ', ingredient).strip()\n",
    "\n",
    "    return ingredient\n",
    "\n",
    "def process_ingredient(ingredient):\n",
    "    cleaned_ingredient = clean_ingredient_text(ingredient)\n",
    "    tokens = word_tokenize(cleaned_ingredient)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    lemmatized_tokens = [lemmatize_word(word, tag) for word, tag in tagged_tokens]\n",
    "    \n",
    "    return \" \".join(lemmatized_tokens)\n",
    "\n",
    "def process_ingredient_list(ingredient_list):\n",
    "    ingredients = [ingredient.strip() for ingredient in ingredient_list.split(',')]\n",
    "    processed_ingredients = [process_ingredient(ingredient) for ingredient in ingredients]\n",
    "    \n",
    "    return ', '.join(processed_ingredients)\n",
    "\n",
    "# Test the function with an example list\n",
    "example_ingredients_list = \"2 (21 ounce) cherry pie filling, 2 egg, 1 (14 ounce), (1/2 - 1) lb corn beef\"\n",
    "processed_ingredients_list = process_ingredient_list(example_ingredients_list)\n",
    "print(processed_ingredients_list)  # Output: \"21 ounce cherry pie filling, 2 egg, 14 ounce, 1 lb corn beef\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read documentation!, use ast literal eval\n",
    "# Try catch with literal eval, converters\n",
    "df = pd.read_csv('Cleaned_Ingredients/recipes_food_com_cleaned.csv')\n",
    "df = df.drop(28217)\n",
    "df = df.drop(84485)\n",
    "df = df.drop(139400)\n",
    "df = df.drop(169196)\n",
    "df['NLP_Ingredients'] = df['IngredientsRaw'].apply(process_ingredient_list)\n",
    "df = df[['ID', 'Name','NLP_Ingredients', 'Cleaned_Ingredients']]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 ounce cherry pie filling, 2 egg, 14 ounce, 1.0 lb corn beef, 0.5 cup biscuit mix\n"
     ]
    }
   ],
   "source": [
    "#current best\n",
    "import re\n",
    "from fractions import Fraction\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import nltk\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def convert_pos_tag_to_wordnet(tag):\n",
    "    tag = tag.upper()\n",
    "    if tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    return None \n",
    "\n",
    "def lemmatize_word(word, tag):\n",
    "    wordnet_tag = convert_pos_tag_to_wordnet(tag)\n",
    "    if wordnet_tag:\n",
    "        return lemmatizer.lemmatize(word, wordnet_tag)\n",
    "    return word  \n",
    "\n",
    "def convert_fractions_to_decimals(text):\n",
    "    \"\"\"\n",
    "    Converts fractions in the text to decimals and multiplies them with the preceding number if present.\n",
    "    Example: '1/2' -> '0.5', '3/4' -> '0.75', '2 1/4' -> '0.5'\n",
    "    \"\"\"\n",
    "    def fraction_to_decimal(match):\n",
    "        try:\n",
    "            whole_number = match.group(1)\n",
    "            fraction = match.group(2)\n",
    "            if whole_number:\n",
    "                return str(round(float(whole_number) * float(Fraction(fraction)), 2))\n",
    "            else:\n",
    "                return str(round(float(Fraction(fraction)), 2))\n",
    "        except ValueError:\n",
    "            return match.group(0)  # Return the original if conversion fails\n",
    "\n",
    "    return re.sub(r'(\\d+)\\s+(\\d+/\\d+)', fraction_to_decimal, text)\n",
    "\n",
    "def clean_ingredient_text(ingredient):\n",
    "    # List of unwanted phrases to remove\n",
    "    unwanted_phrases = [\n",
    "        \"taste\", \"canned\", \"is best\", \"package\", \"or\", \"drain\", \"rinse\", \"with\", \"is\", \"best\",\n",
    "        \"to\", \"cooked\", \"chopped\", \"cook\", \"chop\", \"not\", \"evaporate\", \"cut\", \"into\", \"but\", \"I\",\n",
    "        \"prefer\", \"bite\", \"sized\", \"cubes\", \"and\", \"cans\", \"at\", \"room\", \"temperature\", \"pkge\",\n",
    "        \"in\", \"half\", \"thinly\", \"diced\", \"dice\", \"slice\", \"sliced\", \"strip\", \"strips\", \"large\", \"small\"\n",
    "    ]\n",
    "    \n",
    "    # Remove unwanted phrases\n",
    "    ingredient = re.sub(r'\\b(?:' + '|'.join(unwanted_phrases) + r')\\b', '', ingredient, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Handle ranges like \"(1/2 - 1)\" by keeping the upper bound\n",
    "    ingredient = re.sub(r'\\(([\\d/.\\s]+)-([\\d/.\\s]+)\\)', lambda m: str(max(float(Fraction(m.group(1).strip())), float(Fraction(m.group(2).strip())))), ingredient)\n",
    "    \n",
    "    # Convert fractions to decimals and multiply with preceding number if present\n",
    "    ingredient = convert_fractions_to_decimals(ingredient)\n",
    "    \n",
    "    # Convert standalone fractions to decimals\n",
    "    ingredient = re.sub(r'\\b(\\d+/\\d+)\\b', lambda m: str(round(float(Fraction(m.group(1))), 2)), ingredient)\n",
    "    \n",
    "    # Remove leading quantities in parentheses, e.g., \"2 (21 ounce)\" -> \"21 ounce\"\n",
    "    ingredient = re.sub(r'\\d+\\s*\\(([^)]+)\\)', r'\\1', ingredient)\n",
    "    \n",
    "    # Remove punctuation but keep slashes (for fractions) and collapse multiple spaces\n",
    "    ingredient = re.sub(r'[^\\w\\s/.]', '', ingredient)\n",
    "    ingredient = re.sub(r'\\s+', ' ', ingredient).strip()\n",
    "\n",
    "    return ingredient\n",
    "\n",
    "def process_ingredient(ingredient):\n",
    "    cleaned_ingredient = clean_ingredient_text(ingredient)\n",
    "    tokens = word_tokenize(cleaned_ingredient)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    lemmatized_tokens = [lemmatize_word(word, tag) for word, tag in tagged_tokens]\n",
    "    \n",
    "    return \" \".join(lemmatized_tokens)\n",
    "\n",
    "def process_ingredient_list(ingredient_list):\n",
    "    ingredients = [ingredient.strip() for ingredient in ingredient_list.split(',')]\n",
    "    processed_ingredients = [process_ingredient(ingredient) for ingredient in ingredients]\n",
    "    \n",
    "    return ', '.join(processed_ingredients)\n",
    "\n",
    "# Test the function with an example list\n",
    "example_ingredients_list = \"2 (21 ounce) cherry pie filling, 2 egg, 1 (14 ounce), (1/2 - 1) lb corn beef, 2 1/4 cup biscuit mix\"\n",
    "processed_ingredients_list = process_ingredient_list(example_ingredients_list)\n",
    "print(processed_ingredients_list)  # Output: \"21 ounce cherry pie filling, 2 egg, 14 ounce, 1 lb corn beef, 0.5 cup biscuit mix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 ounce cherry pie filling, 2 egg, 14 ounce, 1.0 lb corn beef, 0.5 cup biscuit mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hijer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hijer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hijer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from fractions import Fraction\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def convert_pos_tag_to_wordnet(tag):\n",
    "    tag = tag.upper()\n",
    "    if tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    return None \n",
    "\n",
    "def lemmatize_word(word, tag):\n",
    "    wordnet_tag = convert_pos_tag_to_wordnet(tag)\n",
    "    if wordnet_tag:\n",
    "        return lemmatizer.lemmatize(word, wordnet_tag)\n",
    "    return word  \n",
    "\n",
    "def convert_fractions_to_decimals(text):\n",
    "    \"\"\"\n",
    "    Converts fractions in the text to decimals and multiplies them with the preceding number if present.\n",
    "    Example: '1/2' -> '0.5', '3/4' -> '0.75', '2 1/4' -> '0.5'\n",
    "    \"\"\"\n",
    "    def fraction_to_decimal(match):\n",
    "        try:\n",
    "            whole_number = match.group(1)\n",
    "            fraction = match.group(2)\n",
    "            if whole_number:\n",
    "                return str(round(float(whole_number) * float(Fraction(fraction)), 2))\n",
    "            else:\n",
    "                return str(round(float(Fraction(fraction)), 2))\n",
    "        except ValueError:\n",
    "            return match.group(0)  # Return the original if conversion fails\n",
    "\n",
    "    return re.sub(r'(\\d+)\\s+(\\d+/\\d+)', fraction_to_decimal, text)\n",
    "\n",
    "def clean_ingredient_text(ingredient):\n",
    "    # List of unwanted phrases to remove\n",
    "    unwanted_phrases = [\n",
    "        \"taste\", \"canned\", \"is best\", \"package\", \"or\", \"drain\", \"rinse\", \"with\", \"is\", \"best\",\n",
    "        \"to\", \"cooked\", \"chopped\", \"cook\", \"chop\", \"not\", \"evaporate\", \"cut\", \"into\", \"but\", \"I\",\n",
    "        \"prefer\", \"bite\", \"sized\", \"cubes\", \"and\", \"cans\", \"at\", \"room\", \"temperature\", \"pkge\",\n",
    "        \"in\", \"half\", \"thinly\", \"diced\", \"dice\", \"slice\", \"sliced\", \"strip\", \"strips\", \"large\", \"small\"\n",
    "    ]\n",
    "    \n",
    "    # Remove unwanted phrases\n",
    "    ingredient = re.sub(r'\\b(?:' + '|'.join(unwanted_phrases) + r')\\b', '', ingredient, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Handle ranges like \"(1/2 - 1)\" by keeping the upper bound\n",
    "    ingredient = re.sub(r'\\(([\\d/.\\s]+)-([\\d/.\\s]+)\\)', lambda m: str(max(float(Fraction(m.group(1).strip())), float(Fraction(m.group(2).strip())))), ingredient)\n",
    "    \n",
    "    # Convert fractions to decimals and multiply with preceding number if present\n",
    "    ingredient = convert_fractions_to_decimals(ingredient)\n",
    "    \n",
    "    # Convert standalone fractions to decimals\n",
    "    ingredient = re.sub(r'\\b(\\d+/\\d+)\\b', lambda m: str(round(float(Fraction(m.group(1))), 2)), ingredient)\n",
    "    \n",
    "    # Remove leading quantities in parentheses, e.g., \"2 (21 ounce)\" -> \"21 ounce\"\n",
    "    ingredient = re.sub(r'\\d+\\s*\\(([^)]+)\\)', r'\\1', ingredient)\n",
    "    \n",
    "    # Remove punctuation but keep slashes (for fractions) and collapse multiple spaces\n",
    "    ingredient = re.sub(r'[^\\w\\s/.]', '', ingredient)\n",
    "    ingredient = re.sub(r'\\s+', ' ', ingredient).strip()\n",
    "\n",
    "    return ingredient\n",
    "\n",
    "def process_ingredient(ingredient):\n",
    "    cleaned_ingredient = clean_ingredient_text(ingredient)\n",
    "    tokens = word_tokenize(cleaned_ingredient)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    lemmatized_tokens = [lemmatize_word(word, tag) for word, tag in tagged_tokens]\n",
    "    \n",
    "    return \" \".join(lemmatized_tokens)\n",
    "\n",
    "def process_ingredient_list(ingredient_list):\n",
    "    ingredients = [ingredient.strip() for ingredient in ingredient_list.split(',')]\n",
    "    processed_ingredients = [process_ingredient(ingredient) for ingredient in ingredients]\n",
    "    \n",
    "    return ', '.join(processed_ingredients)\n",
    "\n",
    "# Test the function with an example list\n",
    "example_ingredients_list = \"2 (21 ounce) cherry pie filling, 2 egg, 1 (14 ounce), (1/2 - 1) lb corn beef, 2 1/4 cup biscuit mix\"\n",
    "processed_ingredients_list = process_ingredient_list(example_ingredients_list)\n",
    "print(processed_ingredients_list)  # Output: \"21 ounce cherry pie filling, 2 egg, 14 ounce, 1 lb corn beef, 0.5 cup biscuit mix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0.1, ID, Name, Description, IngredientsExtracted, IngredientsRaw, Instructions, Servings, TotalTime, Calories, FatContent, SaturatedFatContent, CholesterolContent, SodiumContent, CarbohydrateContent, FiberContent, SugarContent, ProteinContent, Unnamed: 0, RecipeId, Raw_Ingredients, Cleaned_Ingredients, IngredientsRawInGrams]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>IngredientsExtracted</th>\n",
       "      <th>IngredientsRaw</th>\n",
       "      <th>Instructions</th>\n",
       "      <th>Servings</th>\n",
       "      <th>TotalTime</th>\n",
       "      <th>Calories</th>\n",
       "      <th>...</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>FiberContent</th>\n",
       "      <th>SugarContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>Raw_Ingredients</th>\n",
       "      <th>Cleaned_Ingredients</th>\n",
       "      <th>IngredientsRawInGrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28217</th>\n",
       "      <td>28672</td>\n",
       "      <td>537794</td>\n",
       "      <td>Cheesy Fried Chicken Parm Balls</td>\n",
       "      <td>A simple homemade chicken nugget is stuffed wi...</td>\n",
       "      <td>mozzarella string cheese ground chicken italia...</td>\n",
       "      <td>[\"2 mozzarella string cheese\",\"1 lb ground chi...</td>\n",
       "      <td>[\"Cut each mozzarella stick in half lengthwise...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>151.7</td>\n",
       "      <td>...</td>\n",
       "      <td>517.6</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28880</td>\n",
       "      <td>537794</td>\n",
       "      <td>['salt', 'grated parmesan cheese', 'ground chi...</td>\n",
       "      <td>['salt', 'grated parmesan cheese', 'pepper', '...</td>\n",
       "      <td>907.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84485</th>\n",
       "      <td>85741</td>\n",
       "      <td>537778</td>\n",
       "      <td>Steamed Pork &amp; Scallion Dumplings</td>\n",
       "      <td>These dumplings are stuffed with a savory pork...</td>\n",
       "      <td>low sodium soy sauce rice vinegar chili oil sc...</td>\n",
       "      <td>[\"1/2 cup low sodium soy sauce\",\"2 tablespoons...</td>\n",
       "      <td>[\"Whisk together the ingredients for the dippi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>68.9</td>\n",
       "      <td>...</td>\n",
       "      <td>224.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>86535</td>\n",
       "      <td>537778</td>\n",
       "      <td>['low sodium soy sauce', 'garlic cloves', 'sca...</td>\n",
       "      <td>['low sodium soy sauce', 'garlic cloves', 'sca...</td>\n",
       "      <td>226.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139400</th>\n",
       "      <td>141366</td>\n",
       "      <td>537785</td>\n",
       "      <td>Raspberry Almond Shortbread Cookies</td>\n",
       "      <td>A wonderful recipe from Better Homes Garden. T...</td>\n",
       "      <td>butter granulated sugar almond extract seedles...</td>\n",
       "      <td>[\"1 cup butter, softened\",\"2/3 cup granulated ...</td>\n",
       "      <td>[\"In a medium bowl beat butter medium speed fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>113.5</td>\n",
       "      <td>...</td>\n",
       "      <td>46.7</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>142848</td>\n",
       "      <td>537785</td>\n",
       "      <td>['granulated sugar', 'sugar', 'all-purpose flo...</td>\n",
       "      <td>['granulated sugar', 'sugar', 'all-purpose flo...</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169196</th>\n",
       "      <td>171452</td>\n",
       "      <td>537795</td>\n",
       "      <td>Chicken Parm Biscuits</td>\n",
       "      <td>Buttermilk biscuits are filled with fried chic...</td>\n",
       "      <td>panko breadcrumbs grated parmesan cheese garli...</td>\n",
       "      <td>[\"1 1/2 cups panko breadcrumbs\",\"1/3 cup grate...</td>\n",
       "      <td>[\"Preheat oven to 400 F and lightly grease a b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>360.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1204.2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>10.1</td>\n",
       "      <td>173399</td>\n",
       "      <td>537795</td>\n",
       "      <td>['mozzarella cheese', 'salt', 'grated parmesan...</td>\n",
       "      <td>['mozzarella cheese', 'salt', 'grated parmesan...</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0.1      ID                                 Name  \\\n",
       "28217          28672  537794      Cheesy Fried Chicken Parm Balls   \n",
       "84485          85741  537778    Steamed Pork & Scallion Dumplings   \n",
       "139400        141366  537785  Raspberry Almond Shortbread Cookies   \n",
       "169196        171452  537795                Chicken Parm Biscuits   \n",
       "\n",
       "                                              Description  \\\n",
       "28217   A simple homemade chicken nugget is stuffed wi...   \n",
       "84485   These dumplings are stuffed with a savory pork...   \n",
       "139400  A wonderful recipe from Better Homes Garden. T...   \n",
       "169196  Buttermilk biscuits are filled with fried chic...   \n",
       "\n",
       "                                     IngredientsExtracted  \\\n",
       "28217   mozzarella string cheese ground chicken italia...   \n",
       "84485   low sodium soy sauce rice vinegar chili oil sc...   \n",
       "139400  butter granulated sugar almond extract seedles...   \n",
       "169196  panko breadcrumbs grated parmesan cheese garli...   \n",
       "\n",
       "                                           IngredientsRaw  \\\n",
       "28217   [\"2 mozzarella string cheese\",\"1 lb ground chi...   \n",
       "84485   [\"1/2 cup low sodium soy sauce\",\"2 tablespoons...   \n",
       "139400  [\"1 cup butter, softened\",\"2/3 cup granulated ...   \n",
       "169196  [\"1 1/2 cups panko breadcrumbs\",\"1/3 cup grate...   \n",
       "\n",
       "                                             Instructions  Servings  \\\n",
       "28217   [\"Cut each mozzarella stick in half lengthwise...       NaN   \n",
       "84485   [\"Whisk together the ingredients for the dippi...       NaN   \n",
       "139400  [\"In a medium bowl beat butter medium speed fo...       NaN   \n",
       "169196  [\"Preheat oven to 400 F and lightly grease a b...       NaN   \n",
       "\n",
       "        TotalTime  Calories  ...  SodiumContent  CarbohydrateContent  \\\n",
       "28217          50     151.7  ...          517.6                 16.8   \n",
       "84485          70      68.9  ...          224.9                  7.0   \n",
       "139400         40     113.5  ...           46.7                 16.1   \n",
       "169196         60     360.7  ...         1204.2                 41.0   \n",
       "\n",
       "        FiberContent  SugarContent  ProteinContent  Unnamed: 0  RecipeId  \\\n",
       "28217            0.8           0.8            10.0       28880    537794   \n",
       "84485            0.5           1.1             3.4       86535    537778   \n",
       "139400           0.2           9.9             0.8      142848    537785   \n",
       "169196           1.5           4.8            10.1      173399    537795   \n",
       "\n",
       "                                          Raw_Ingredients  \\\n",
       "28217   ['salt', 'grated parmesan cheese', 'ground chi...   \n",
       "84485   ['low sodium soy sauce', 'garlic cloves', 'sca...   \n",
       "139400  ['granulated sugar', 'sugar', 'all-purpose flo...   \n",
       "169196  ['mozzarella cheese', 'salt', 'grated parmesan...   \n",
       "\n",
       "                                      Cleaned_Ingredients  \\\n",
       "28217   ['salt', 'grated parmesan cheese', 'pepper', '...   \n",
       "84485   ['low sodium soy sauce', 'garlic cloves', 'sca...   \n",
       "139400  ['granulated sugar', 'sugar', 'all-purpose flo...   \n",
       "169196  ['mozzarella cheese', 'salt', 'grated parmesan...   \n",
       "\n",
       "        IngredientsRawInGrams  \n",
       "28217                 907.184  \n",
       "84485                 226.796  \n",
       "139400                  240.0  \n",
       "169196                  360.0  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_entries = df[df['IngredientsRaw'] == '.']\n",
    "print(invalid_entries)\n",
    "empty_rows = df[df.isnull().any(axis=1)]\n",
    "empty_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ingredient list: 2 (21 ounce) cherry pie filling, 2 egg, 1 (14 ounce), (1/2 - 1) lb corn beef, 2 1/4 cup biscuit mix\n",
      "Split ingredients: ['2 (21 ounce) cherry pie filling', '2 egg', '1 (14 ounce)', '(1/2 - 1) lb corn beef', '2 1/4 cup biscuit mix']\n",
      "Original ingredient: 2 (21 ounce) cherry pie filling\n",
      "After removing unwanted phrases: 2 (21 ounce) cherry pie filling\n",
      "After handling ranges: 2 (21 ounce) cherry pie filling\n",
      "After converting fractions to decimals: 2 (21 ounce) cherry pie filling\n",
      "After removing standalone fractions: 2 (21 ounce) cherry pie filling\n",
      "After removing leading quantities: 21 ounce cherry pie filling\n",
      "Final cleaned ingredient: 21 ounce cherry pie filling\n",
      "Cleaned ingredient: 21 ounce cherry pie filling\n",
      "Tokens: ['21', 'ounce', 'cherry', 'pie', 'filling']\n",
      "Tagged Tokens: [('21', 'CD'), ('ounce', 'NN'), ('cherry', 'NN'), ('pie', 'NN'), ('filling', 'NN')]\n",
      "Lemmatized Tokens: ['21', 'ounce', 'cherry', 'pie', 'filling']\n",
      "Original ingredient: 2 egg\n",
      "After removing unwanted phrases: 2 egg\n",
      "After handling ranges: 2 egg\n",
      "After converting fractions to decimals: 2 egg\n",
      "After removing standalone fractions: 2 egg\n",
      "After removing leading quantities: 2 egg\n",
      "Final cleaned ingredient: 2 egg\n",
      "Cleaned ingredient: 2 egg\n",
      "Tokens: ['2', 'egg']\n",
      "Tagged Tokens: [('2', 'CD'), ('egg', 'NN')]\n",
      "Lemmatized Tokens: ['2', 'egg']\n",
      "Original ingredient: 1 (14 ounce)\n",
      "After removing unwanted phrases: 1 (14 ounce)\n",
      "After handling ranges: 1 (14 ounce)\n",
      "After converting fractions to decimals: 1 (14 ounce)\n",
      "After removing standalone fractions: 1 (14 ounce)\n",
      "After removing leading quantities: 14 ounce\n",
      "Final cleaned ingredient: 14 ounce\n",
      "Cleaned ingredient: 14 ounce\n",
      "Tokens: ['14', 'ounce']\n",
      "Tagged Tokens: [('14', 'CD'), ('ounce', 'NN')]\n",
      "Lemmatized Tokens: ['14', 'ounce']\n",
      "Original ingredient: (1/2 - 1) lb corn beef\n",
      "After removing unwanted phrases: (1/2 - 1) lb corn beef\n",
      "After handling ranges: 1.0 lb corn beef\n",
      "After converting fractions to decimals: 1.0 lb corn beef\n",
      "After removing standalone fractions: 1.0 lb corn beef\n",
      "After removing leading quantities: 1.0 lb corn beef\n",
      "Final cleaned ingredient: 1.0 lb corn beef\n",
      "Cleaned ingredient: 1.0 lb corn beef\n",
      "Tokens: ['1.0', 'lb', 'corn', 'beef']\n",
      "Tagged Tokens: [('1.0', 'CD'), ('lb', 'JJ'), ('corn', 'NN'), ('beef', 'NN')]\n",
      "Lemmatized Tokens: ['1.0', 'lb', 'corn', 'beef']\n",
      "Original ingredient: 2 1/4 cup biscuit mix\n",
      "After removing unwanted phrases: 2 1/4 cup biscuit mix\n",
      "After handling ranges: 2 1/4 cup biscuit mix\n",
      "Debug: whole_number = 2, fraction = 1/4\n",
      "After converting fractions to decimals: 0.5 cup biscuit mix\n",
      "After removing standalone fractions: 0.5 cup biscuit mix\n",
      "After removing leading quantities: 0.5 cup biscuit mix\n",
      "Final cleaned ingredient: 0.5 cup biscuit mix\n",
      "Cleaned ingredient: 0.5 cup biscuit mix\n",
      "Tokens: ['0.5', 'cup', 'biscuit', 'mix']\n",
      "Tagged Tokens: [('0.5', 'CD'), ('cup', 'NN'), ('biscuit', 'NN'), ('mix', 'NN')]\n",
      "Lemmatized Tokens: ['0.5', 'cup', 'biscuit', 'mix']\n",
      "Processed ingredients: ['21 ounce cherry pie filling', '2 egg', '14 ounce', '1.0 lb corn beef', '0.5 cup biscuit mix']\n",
      "21 ounce cherry pie filling, 2 egg, 14 ounce, 1.0 lb corn beef, 0.5 cup biscuit mix\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from fractions import Fraction\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import nltk\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def convert_pos_tag_to_wordnet(tag):\n",
    "    tag = tag.upper()\n",
    "    if tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    return None \n",
    "\n",
    "def lemmatize_word(word, tag):\n",
    "    wordnet_tag = convert_pos_tag_to_wordnet(tag)\n",
    "    if wordnet_tag:\n",
    "        return lemmatizer.lemmatize(word, wordnet_tag)\n",
    "    return word  \n",
    "\n",
    "def convert_fractions_to_decimals(text):\n",
    "    \"\"\"\n",
    "    Converts fractions in the text to decimals and multiplies them with the preceding number if present.\n",
    "    Example: '1/2' -> '0.5', '3/4' -> '0.75', '2 1/4' -> '0.5'\n",
    "    \"\"\"\n",
    "    def fraction_to_decimal(match):\n",
    "        try:\n",
    "            whole_number = match.group(1)\n",
    "            fraction = match.group(2)\n",
    "            print(f\"Debug: whole_number = {whole_number}, fraction = {fraction}\")  # Debugging here\n",
    "            if whole_number:\n",
    "                return str(round(float(whole_number) * float(Fraction(fraction)), 2))\n",
    "            else:\n",
    "                return str(round(float(Fraction(fraction)), 2))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in fraction_to_decimal: {e}, match = {match.group(0)}\")  # Debugging error\n",
    "            return match.group(0)  # Return the original if conversion fails\n",
    "\n",
    "    return re.sub(r'(\\d+)\\s+(\\d+/\\d+)', fraction_to_decimal, text)\n",
    "\n",
    "def clean_ingredient_text(ingredient):\n",
    "    # List of unwanted phrases to remove\n",
    "    unwanted_phrases = [\n",
    "        \"taste\", \"canned\", \"is best\", \"package\", \"or\", \"drain\", \"rinse\", \"with\", \"is\", \"best\",\n",
    "        \"to\", \"cooked\", \"chopped\", \"cook\", \"chop\", \"not\", \"evaporate\", \"cut\", \"into\", \"but\", \"I\",\n",
    "        \"prefer\", \"bite\", \"sized\", \"cubes\", \"and\", \"cans\", \"at\", \"room\", \"temperature\", \"pkge\",\n",
    "        \"in\", \"half\", \"thinly\", \"diced\", \"dice\", \"slice\", \"sliced\", \"strip\", \"strips\", \"large\", \"small\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Original ingredient: {ingredient}\")  # Debug start\n",
    "\n",
    "    # Remove unwanted phrases\n",
    "    ingredient = re.sub(r'\\b(?:' + '|'.join(unwanted_phrases) + r')\\b', '', ingredient, flags=re.IGNORECASE)\n",
    "    print(f\"After removing unwanted phrases: {ingredient}\")  # Debug step\n",
    "\n",
    "    # Handle ranges like \"(1/2 - 1)\" by keeping the upper bound\n",
    "    ingredient = re.sub(r'\\(([\\d/.\\s]+)-([\\d/.\\s]+)\\)', \n",
    "                        lambda m: str(max(float(Fraction(m.group(1).strip())), float(Fraction(m.group(2).strip())))), \n",
    "                        ingredient)\n",
    "    print(f\"After handling ranges: {ingredient}\")  # Debug step\n",
    "\n",
    "    # Convert fractions to decimals and multiply with preceding number if present\n",
    "    ingredient = convert_fractions_to_decimals(ingredient)\n",
    "    print(f\"After converting fractions to decimals: {ingredient}\")  # Debug step\n",
    "\n",
    "    # Convert standalone fractions to decimals\n",
    "    ingredient = re.sub(r'\\b(\\d+/\\d+)\\b', lambda m: str(round(float(Fraction(m.group(1))), 2)), ingredient)\n",
    "    print(f\"After removing standalone fractions: {ingredient}\")  # Debug step\n",
    "\n",
    "    # Remove leading quantities in parentheses, e.g., \"2 (21 ounce)\" -> \"21 ounce\"\n",
    "    ingredient = re.sub(r'\\d+\\s*\\(([^)]+)\\)', r'\\1', ingredient)\n",
    "    print(f\"After removing leading quantities: {ingredient}\")  # Debug step\n",
    "\n",
    "    # Remove punctuation but keep slashes (for fractions) and collapse multiple spaces\n",
    "    ingredient = re.sub(r'[^\\w\\s/.]', '', ingredient)\n",
    "    ingredient = re.sub(r'\\s+', ' ', ingredient).strip()\n",
    "    print(f\"Final cleaned ingredient: {ingredient}\")  # Debug final output\n",
    "\n",
    "    return ingredient\n",
    "\n",
    "def process_ingredient(ingredient):\n",
    "    cleaned_ingredient = clean_ingredient_text(ingredient)\n",
    "    print(f\"Cleaned ingredient: {cleaned_ingredient}\")  # Debug cleaned output\n",
    "\n",
    "    tokens = word_tokenize(cleaned_ingredient)\n",
    "    print(f\"Tokens: {tokens}\")  # Debug tokens\n",
    "\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    print(f\"Tagged Tokens: {tagged_tokens}\")  # Debug tagging\n",
    "\n",
    "    lemmatized_tokens = [lemmatize_word(word, tag) for word, tag in tagged_tokens]\n",
    "    print(f\"Lemmatized Tokens: {lemmatized_tokens}\")  # Debug lemmatization\n",
    "\n",
    "    return \" \".join(lemmatized_tokens)\n",
    "\n",
    "def process_ingredient_list(ingredient_list):\n",
    "    print(f\"Original ingredient list: {ingredient_list}\")  # Debug input\n",
    "\n",
    "    ingredients = [ingredient.strip() for ingredient in ingredient_list.split(',')]\n",
    "    print(f\"Split ingredients: {ingredients}\")  # Debug splitting\n",
    "\n",
    "    processed_ingredients = []\n",
    "    for ingredient in ingredients:\n",
    "        try:\n",
    "            processed = process_ingredient(ingredient)\n",
    "            processed_ingredients.append(processed)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing ingredient: {ingredient}, Error: {e}\")  # Debug error\n",
    "\n",
    "    print(f\"Processed ingredients: {processed_ingredients}\")  # Debug final output\n",
    "    return ', '.join(processed_ingredients)\n",
    "\n",
    "# Test the function with an example list\n",
    "example_ingredients_list = \"2 (21 ounce) cherry pie filling, 2 egg, 1 (14 ounce), (1/2 - 1) lb corn beef, 2 1/4 cup biscuit mix\"\n",
    "processed_ingredients_list = process_ingredient_list(example_ingredients_list)\n",
    "print(processed_ingredients_list)  # Output: Processed result with debug info\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
